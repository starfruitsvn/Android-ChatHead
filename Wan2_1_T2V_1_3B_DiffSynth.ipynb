{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/starfruitsvn/Android-ChatHead/blob/master/Wan2_1_T2V_1_3B_DiffSynth.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note**: You will need at least the L4 which comes with a RAM above 50GB to run this because of the text encoder checkpoint which causes a memory spike in the RAM up to 22GB during loading. This will crash the free T4 which is provided with a RAM of just 12.7GB."
      ],
      "metadata": {
        "id": "RXjAHic0nJjc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DOWNLOAD LIBRARIES & MODELS**"
      ],
      "metadata": {
        "id": "Q17ff9G1j_bL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "9-CAvpGRJf23"
      },
      "outputs": [],
      "source": [
        "# @title\n",
        "!git clone https://github.com/Isi-dev/DiffSynth-Studio.git\n",
        "%cd DiffSynth-Studio\n",
        "!pip install -e .\n",
        "!pip install \"huggingface_hub[cli]\"\n",
        "!apt-get install -y aria2\n",
        "import os\n",
        "from huggingface_hub import list_repo_files\n",
        "\n",
        "repo_id = \"Wan-AI/Wan2.1-T2V-1.3B\"\n",
        "all_files = list_repo_files(repo_id)\n",
        "base_url = f\"https://huggingface.co/{repo_id}/resolve/main/\"\n",
        "\n",
        "with open(\"file_list.txt\", \"w\") as f:\n",
        "    for file_path in all_files:\n",
        "        full_url = f\"{base_url}{file_path}\"\n",
        "        save_path = f\"models/Wan-AI/Wan2.1-T2V-1.3B/{file_path}\"\n",
        "        os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
        "        f.write(f\"{full_url}\\n out={save_path}\\n\")\n",
        "!aria2c -x 16 -s 16 -i file_list.txt --continue=true --auto-file-renaming=false\n",
        "\n",
        "print(\"✅ All models downloaded successfully!\")\n",
        "\n",
        "import torch\n",
        "from diffsynth import ModelManager, WanVideoPipeline\n",
        "\n",
        "# Initialize model manager and load the model\n",
        "model_manager = ModelManager(device=\"cuda\")\n",
        "model_manager.load_models(\n",
        "    [\n",
        "        \"models/Wan-AI/Wan2.1-T2V-1.3B/diffusion_pytorch_model.safetensors\",\n",
        "        \"models/Wan-AI/Wan2.1-T2V-1.3B/models_t5_umt5-xxl-enc-bf16.pth\",\n",
        "        \"models/Wan-AI/Wan2.1-T2V-1.3B/Wan2.1_VAE.pth\",\n",
        "    ],\n",
        "    torch_dtype=torch.bfloat16  # Use torch.float8_e4m3fn for FP8 quantization if needed\n",
        ")\n",
        "\n",
        "# Initialize the video pipeline\n",
        "pipe = WanVideoPipeline.from_model_manager(model_manager, torch_dtype=torch.bfloat16, device=\"cuda\")\n",
        "pipe.enable_vram_management(num_persistent_param_in_dit=None)\n",
        "print(\"✅ All models loaded successfully!\")\n",
        "from diffsynth import save_video\n",
        "from diffsynth import VideoData\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**RUN TEXT TO VIDEO**"
      ],
      "metadata": {
        "id": "FpnKloqwkPOg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"A 25 years old blonde walking in the street.\" # @param {type:\"string\"}\n",
        "sample_steps = 30 # @param {\"type\":\"number\"}\n",
        "Instruction = \"choose from  '480*832' & '832*480' for Width & Height\" # @param {\"type\":\"string\"}\n",
        "width = 480 # @param {\"type\":\"number\"}\n",
        "height = 832 # @param {\"type\":\"number\"}\n",
        "seed = 1 # @param {\"type\":\"number\"}\n",
        "\n",
        "# Generate video from text prompt\n",
        "video = pipe(\n",
        "    prompt=prompt,\n",
        "    negative_prompt=\"色调艳丽，过曝，静态，细节模糊不清，字幕，风格，作品，画作，画面，静止，整体发灰，最差质量，低质量，JPEG压缩残留，丑陋的，残缺的，多余的手指，画得不好的手部，画得不好的脸部，畸形的，毁容的，形态畸形的肢体，手指融合，静止不动的画面，杂乱的背景，三条腿，背景人很多，倒着走\",\n",
        "    height = height,\n",
        "    width = width,\n",
        "    num_inference_steps=sample_steps,\n",
        "    seed=seed, tiled=True\n",
        ")\n",
        "\n",
        "# Save the generated video\n",
        "save_video(video, \"video1.mp4\", fps=15, quality=5)\n",
        "\n",
        "from IPython.display import display as displayVid, Video as outVid\n",
        "import os\n",
        "\n",
        "# Function to display video\n",
        "def show_video(video_path):\n",
        "    if os.path.exists(video_path):\n",
        "        displayVid(outVid(video_path, embed=True))\n",
        "    else:\n",
        "        print(f\"Error: {video_path} not found!\")\n",
        "\n",
        "# Show the video\n",
        "show_video(\"video1.mp4\")\n"
      ],
      "metadata": {
        "collapsed": true,
        "cellView": "form",
        "id": "UY1xCtz1OqSt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**RUN TEXT TO IMAGE**"
      ],
      "metadata": {
        "id": "z92WKT5b-1et"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"A highly detailed, realistic AI-generated portrait of a very beautiful female soldier representing Canada. She has long hair, a confident and friendly smile, and striking facial features. She is wearing a camouflage military uniform with an open front, revealing her huge cleavage. She holds a modern assault rifle in a relaxed yet ready position. The background shows a slightly blurred battlefield with other soldiers in formation, creating a sense of military action. The Canadian flag is displayed on her uniform on her shoulder. The lighting is natural, with a warm and slightly cinematic tone. The image should have a sharp focus on her face and outfit while maintaining a professional military aesthetic.\" # @param {type:\"string\"}\n",
        "sample_steps = 30 # @param {\"type\":\"number\"}\n",
        "Instruction = \"choose from '720*1280', '1280*720', '480*832', '832*480', '1024*1024 for Width & Height\" # @param {\"type\":\"string\"}\n",
        "width = 720 # @param {\"type\":\"number\"}\n",
        "height = 1280 # @param {\"type\":\"number\"}\n",
        "seed = 48 # @param {\"type\":\"number\"}\n",
        "displayWidth = 480 # @param {\"type\":\"number\"}\n",
        "\n",
        "# Generate video from text prompt\n",
        "video = pipe(\n",
        "    prompt=prompt,\n",
        "    negative_prompt=\"色调艳丽，过曝，静态，细节模糊不清，字幕，风格，作品，画作，画面，静止，整体发灰，最差质量，低质量，JPEG压缩残留，丑陋的，残缺的，多余的手指，画得不好的手部，画得不好的脸部，畸形的，毁容的，形态畸形的肢体，手指融合，静止不动的画面，杂乱的背景，三条腿，背景人很多，倒着走\",\n",
        "    height = height,\n",
        "    width = width,\n",
        "    num_frames=1,\n",
        "    num_inference_steps=sample_steps,\n",
        "    seed=seed, tiled=True\n",
        ")\n",
        "\n",
        "# Save the generated video\n",
        "save_video(video, \"vid.mp4\", fps=15, quality=5)\n",
        "\n",
        "import cv2\n",
        "import os\n",
        "from IPython.display import display as displayVid, Image as outImg\n",
        "\n",
        "def show_image(video_path, display_width=480):\n",
        "    if not os.path.exists(video_path):\n",
        "        print(f\"Error: {video_path} not found!\")\n",
        "        return\n",
        "\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    success, frame = cap.read()\n",
        "    cap.release()\n",
        "\n",
        "    if success:\n",
        "        image_path = \"single_frame.png\"\n",
        "        cv2.imwrite(image_path, frame)\n",
        "        displayVid(outImg(image_path, width=display_width))\n",
        "    else:\n",
        "        print(\"Error: Could not read the frame.\")\n",
        "\n",
        "show_image(\"vid.mp4\", display_width=displayWidth)\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "SRIWM1Ir-6R8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**RUN VIDEO TO VIDEO**(Experimental)"
      ],
      "metadata": {
        "id": "d8pCP7AEkWDy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"The woman wears a crown.\" # @param {type:\"string\"}\n",
        "sample_steps = 30 # @param {\"type\":\"number\"}\n",
        "Instruction = \"choose from  '480*832' & '832*480' for Width & Height\" # @param {\"type\":\"string\"}\n",
        "width = 480 # @param {\"type\":\"number\"}\n",
        "height = 832 # @param {\"type\":\"number\"}\n",
        "seed = 1 # @param {\"type\":\"number\"}\n",
        "denoising_strength = 0.7 # @param {\"type\":\"number\"}\n",
        "upload_a_video = False # @param {\"type\":\"boolean\"}\n",
        "\n",
        "if upload_a_video:\n",
        "    from google.colab import files\n",
        "    import cv2\n",
        "\n",
        "    # Upload video\n",
        "    uploaded = files.upload()\n",
        "    video_path = list(uploaded.keys())[0]  # Get uploaded file name (video path)\n",
        "\n",
        "    # Check if the video was uploaded correctly\n",
        "    if not video_path:\n",
        "        print(\"Error: No video uploaded.\")\n",
        "    else:\n",
        "        print(f\"Successfully uploaded: {video_path}\")\n",
        "\n",
        "    # Use the uploaded video file path directly for VideoData\n",
        "    video = VideoData(video_path, height=height, width=width)\n",
        "else:\n",
        "    # Load the previously generated video\n",
        "    video = VideoData(\"video1.mp4\", height=height, width=width)\n",
        "\n",
        "# Modify the video with a new prompt\n",
        "video = pipe(\n",
        "    prompt=prompt,\n",
        "    negative_prompt=\"色调艳丽，过曝，静态，细节模糊不清，字幕，风格，作品，画作，画面，静止，整体发灰，最差质量，低质量，JPEG压缩残留，丑陋的，残缺的，多余的手指，画得不好的手部，画得不好的脸部，畸形的，毁容的，形态畸形的肢体，手指融合，静止不动的画面，杂乱的背景，三条腿，背景人很多，倒着走\",\n",
        "    input_video=video, denoising_strength=denoising_strength,\n",
        "    height = height,\n",
        "    width = width,\n",
        "    num_inference_steps=sample_steps,\n",
        "    seed=seed, tiled=True\n",
        ")\n",
        "\n",
        "# Save the modified video\n",
        "save_video(video, \"video2.mp4\", fps=15, quality=5)\n",
        "\n",
        "# Function to display video\n",
        "def show_video(video_path):\n",
        "    if os.path.exists(video_path):\n",
        "        displayVid(outVid(video_path, embed=True))\n",
        "    else:\n",
        "        print(f\"Error: {video_path} not found!\")\n",
        "\n",
        "# Show the video\n",
        "show_video(\"video2.mp4\")\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "PXUDq-uiMPkC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}